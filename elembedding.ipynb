{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import click as ck\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import function\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    ")\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from tensorflow.keras import backend as K\n",
    "from scipy.stats import rankdata\n",
    "import os\n",
    "\n",
    "from elembeddings.elembedding import (\n",
    "    ELModel, load_data, load_valid_data, Generator, MyModelCheckpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 256\n",
    "embedding_size = 50\n",
    "margin = -0.1\n",
    "reg_norm = 1\n",
    "learning_rate = 1e-3\n",
    "epochs = 200\n",
    "org_id = '9606'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nf2 12090\n",
      "nf3_neg 1076572\n",
      "nf4 12088\n",
      "disjoint 30\n",
      "nf3 836948\n",
      "top 1\n",
      "nf1 85119\n"
     ]
    }
   ],
   "source": [
    "# Load training data in (h, l, t) triples\n",
    "# classes and relations are entity to id mappings\n",
    "train_data, classes, relations = load_data('data/train/9606.classes-normalized.owl')\n",
    "valid_data = load_valid_data('data/valid/9606.protein.links.v11.0.txt', classes, relations)\n",
    "for key, value in train_data.items():\n",
    "    print('{0} {1}'.format(key, len(value)))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes 83079\n",
      "Total number of relations 10\n"
     ]
    }
   ],
   "source": [
    "# Filter out protein classes\n",
    "proteins = {}\n",
    "for k, v in classes.items():\n",
    "    if k.startswith('<http://9606'):\n",
    "        proteins[k] = v\n",
    "\n",
    "# Prepare data for training the model\n",
    "nb_classes = len(classes)\n",
    "nb_relations = len(relations)\n",
    "nb_train_data = 0\n",
    "for key, val in train_data.items():\n",
    "    nb_train_data = max(len(val), nb_train_data)\n",
    "train_steps = int(math.ceil(nb_train_data / (1.0 * batch_size)))\n",
    "train_generator = Generator(train_data, batch_size, steps=train_steps)\n",
    "\n",
    "# id to entity maps\n",
    "cls_dict = {v: k for k, v in classes.items()}\n",
    "rel_dict = {v: k for k, v in relations.items()}\n",
    "\n",
    "cls_list = []\n",
    "rel_list = []\n",
    "for i in range(nb_classes):\n",
    "    cls_list.append(cls_dict[i])\n",
    "for i in range(nb_relations):\n",
    "    rel_list.append(rel_dict[i])\n",
    "\n",
    "        \n",
    "print('Total number of classes', nb_classes)\n",
    "print('Total number of relations', nb_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ELEmbeddings Model and Train\n",
    "\n",
    "Embeddings are saved depending on mean rank evaluation on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slater/.local/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4203/4206 [============================>.] - ETA: 0s - loss: 14.3501\n",
      " Validation 1 4391.820465805506\n",
      "\n",
      "\n",
      " Saving embeddings 1 4391.820465805506\n",
      "\n",
      "4206/4206 [==============================] - 435s 103ms/step - loss: 14.3420\n",
      "Epoch 2/200\n",
      "4205/4206 [============================>.] - ETA: 0s - loss: 1.4248\n",
      " Validation 2 1912.317386130611\n",
      "\n",
      "\n",
      " Saving embeddings 2 1912.317386130611\n",
      "\n",
      "4206/4206 [==============================] - 432s 103ms/step - loss: 1.4246\n",
      "Epoch 3/200\n",
      "4203/4206 [============================>.] - ETA: 0s - loss: 0.3517\n",
      " Validation 3 2851.8709343052583\n",
      "\n",
      "4206/4206 [==============================] - 427s 102ms/step - loss: 0.3516\n",
      "Epoch 4/200\n",
      "4204/4206 [============================>.] - ETA: 0s - loss: 0.1665\n",
      " Validation 4 4204.653766708078\n",
      "\n",
      "4206/4206 [==============================] - 412s 98ms/step - loss: 0.1665\n",
      "Epoch 5/200\n",
      "4205/4206 [============================>.] - ETA: 0s - loss: 0.1156\n",
      " Validation 5 4918.197941145654\n",
      "\n",
      "4206/4206 [==============================] - 411s 98ms/step - loss: 0.1156\n",
      "Epoch 6/200\n",
      "4204/4206 [============================>.] - ETA: 0s - loss: 0.0937\n",
      " Validation 6 5383.235271445464\n",
      "\n",
      "4206/4206 [==============================] - 415s 99ms/step - loss: 0.0937\n",
      "Epoch 7/200\n",
      "4205/4206 [============================>.] - ETA: 0s - loss: 0.0814\n",
      " Validation 7 5677.935435345537\n",
      "\n",
      "4206/4206 [==============================] - 413s 98ms/step - loss: 0.0814\n",
      "Epoch 8/200\n",
      "4205/4206 [============================>.] - ETA: 0s - loss: 0.0738\n",
      " Validation 8 5857.975575895463\n",
      "\n",
      "4206/4206 [==============================] - 410s 98ms/step - loss: 0.0738\n",
      "Epoch 9/200\n",
      "4205/4206 [============================>.] - ETA: 0s - loss: 0.0690\n",
      " Validation 9 5949.127969285575\n",
      "\n",
      "4206/4206 [==============================] - 414s 98ms/step - loss: 0.0690\n",
      "Epoch 10/200\n",
      "4204/4206 [============================>.] - ETA: 0s - loss: 0.0652\n",
      " Validation 10 6056.210761274679\n",
      "\n",
      "4206/4206 [==============================] - 411s 98ms/step - loss: 0.0652\n",
      "Epoch 11/200\n",
      "4204/4206 [============================>.] - ETA: 0s - loss: 0.0623\n",
      " Validation 11 6151.055538924396\n",
      "\n",
      "4206/4206 [==============================] - 412s 98ms/step - loss: 0.0623\n",
      "Epoch 12/200\n",
      "4204/4206 [============================>.] - ETA: 0s - loss: 0.0602\n",
      " Validation 12 6171.921601131584\n",
      "\n",
      "4206/4206 [==============================] - 412s 98ms/step - loss: 0.0602\n",
      "Epoch 13/200\n",
      "4203/4206 [============================>.] - ETA: 0s - loss: 0.0585\n",
      " Validation 13 6088.111597988295\n",
      "\n",
      "4206/4206 [==============================] - 411s 98ms/step - loss: 0.0585\n",
      "Epoch 14/200\n",
      "4205/4206 [============================>.] - ETA: 0s - loss: 0.0571\n",
      " Validation 14 6157.211206573965\n",
      "\n",
      "4206/4206 [==============================] - 414s 98ms/step - loss: 0.0571\n",
      "Epoch 15/200\n",
      "4203/4206 [============================>.] - ETA: 0s - loss: 0.0561\n",
      " Validation 15 6134.430873834363\n",
      "\n",
      "4206/4206 [==============================] - 414s 98ms/step - loss: 0.0561\n",
      "Epoch 16/200\n",
      "4203/4206 [============================>.] - ETA: 0s - loss: 0.0550\n",
      " Validation 16 6199.641990600069\n",
      "\n",
      "4206/4206 [==============================] - 416s 99ms/step - loss: 0.0550\n",
      "Epoch 17/200\n",
      "4204/4206 [============================>.] - ETA: 0s - loss: 0.0541\n",
      " Validation 17 6141.892267508869\n",
      "\n",
      "4206/4206 [==============================] - 409s 97ms/step - loss: 0.0541\n",
      "Epoch 18/200\n",
      "4204/4206 [============================>.] - ETA: 0s - loss: 0.0533\n",
      " Validation 18 6272.808304270383\n",
      "\n",
      "4206/4206 [==============================] - 414s 98ms/step - loss: 0.0533\n",
      "Epoch 19/200\n",
      "4204/4206 [============================>.] - ETA: 0s - loss: 0.0527"
     ]
    }
   ],
   "source": [
    "# Input layers for each loss type\n",
    "nf1 = Input(shape=(2,), dtype=np.int32)\n",
    "nf2 = Input(shape=(3,), dtype=np.int32)\n",
    "nf3 = Input(shape=(3,), dtype=np.int32)\n",
    "nf4 = Input(shape=(3,), dtype=np.int32)\n",
    "dis = Input(shape=(3,), dtype=np.int32)\n",
    "top = Input(shape=(1,), dtype=np.int32)\n",
    "nf3_neg = Input(shape=(3,), dtype=np.int32)\n",
    "\n",
    "# Build model\n",
    "el_model = ELModel(nb_classes, nb_relations, embedding_size, batch_size, margin, reg_norm)\n",
    "out = el_model([nf1, nf2, nf3, nf4, dis, top, nf3_neg])\n",
    "model = tf.keras.Model(inputs=[nf1, nf2, nf3, nf4, dis, top, nf3_neg], outputs=out)\n",
    "optimizer = optimizers.Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Pandas files to store embeddings\n",
    "if not os.path.exists('data/elembeddings'):\n",
    "    os.makedirs('data/elembeddings')\n",
    "out_classes_file = 'data/elembeddings/9606_cls_embeddings.pkl'\n",
    "out_relations_file = 'data/elembeddings/9606_rel_embeddings.pkl'\n",
    "\n",
    "# ModelCheckpoint which runs at the end of each epoch\n",
    "checkpointer = MyModelCheckpoint(\n",
    "    out_classes_file=out_classes_file,\n",
    "    out_relations_file=out_relations_file,\n",
    "    cls_list=cls_list,\n",
    "    rel_list=rel_list,\n",
    "    valid_data=valid_data,\n",
    "    proteins=proteins,\n",
    "    monitor='loss')\n",
    "\n",
    "# Start training\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    workers=12,\n",
    "    callbacks=[checkpointer,])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of embeddings on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(data_file, classes, relations):\n",
    "    data = []\n",
    "    rel = '<http://interacts>'\n",
    "    with open(data_file, 'r') as f:\n",
    "        for line in f:\n",
    "            it = line.strip().split()\n",
    "            id1 = '<http://{0}>'.format(it[0])\n",
    "            id2 = '<http://{0}>'.format(it[1])\n",
    "            if id1 not in classes or id2 not in classes or rel not in relations:\n",
    "                continue\n",
    "            data.append((id1, rel, id2))\n",
    "    return data\n",
    "\n",
    "def compute_rank_roc(ranks, n_prots):\n",
    "    auc_x = list(ranks.keys())\n",
    "    auc_x.sort()\n",
    "    auc_y = []\n",
    "    tpr = 0\n",
    "    sum_rank = sum(ranks.values())\n",
    "    for x in auc_x:\n",
    "        tpr += ranks[x]\n",
    "        auc_y.append(tpr / sum_rank)\n",
    "    auc_x.append(n_prots)\n",
    "    auc_y.append(1)\n",
    "    auc = np.trapz(auc_y, auc_x) / n_prots\n",
    "    return auc\n",
    "\n",
    "\n",
    "# Pandas files to store embeddings\n",
    "out_classes_file = 'data/elembeddings/9606_cls_embeddings.pkl'\n",
    "out_relations_file = 'data/elembeddings/9606_rel_embeddings.pkl'\n",
    "\n",
    "cls_df = pd.read_pickle(out_classes_file)\n",
    "rel_df = pd.read_pickle(out_relations_file)\n",
    "nb_classes = len(cls_df)\n",
    "nb_relations = len(rel_df)\n",
    "embeds_list = cls_df['embeddings'].values\n",
    "rembeds_list = rel_df['embeddings'].values\n",
    "size = len(embeds_list[0])\n",
    "embeds = np.zeros((nb_classes, size), dtype=np.float32)\n",
    "for i, emb in enumerate(embeds_list):\n",
    "    embeds[i, :] = emb\n",
    "\n",
    "rs = np.abs(embeds[:, -1]).reshape(-1, 1)\n",
    "embeds = embeds[:, :-1]\n",
    "prot_index = list(proteins.values())\n",
    "prot_rs = rs[prot_index, :]\n",
    "prot_embeds = embeds[prot_index, :]\n",
    "prot_dict = {v: k for k, v in enumerate(prot_index)}\n",
    "    \n",
    "rsize = len(rembeds_list[0])\n",
    "rembeds = np.zeros((nb_relations, rsize), dtype=np.float32)\n",
    "for i, emb in enumerate(rembeds_list):\n",
    "    rembeds[i, :] = emb\n",
    "\n",
    "train_data = load_test_data('data/train/9606.protein.links.v11.0.txt', classes, relations)\n",
    "valid_data = load_test_data('data/valid/9606.protein.links.v11.0.txt', classes, relations)\n",
    "trlabels = {}\n",
    "for c, r, d in train_data:\n",
    "    c, r, d = prot_dict[classes[c]], relations[r], prot_dict[classes[d]]\n",
    "    if r not in trlabels:\n",
    "        trlabels[r] = np.ones((len(prot_embeds), len(prot_embeds)), dtype=np.int32)\n",
    "    trlabels[r][c, d] = 1000\n",
    "for c, r, d in valid_data:\n",
    "    c, r, d = prot_dict[classes[c]], relations[r], prot_dict[classes[d]]\n",
    "    if r not in trlabels:\n",
    "        trlabels[r] = np.ones((len(prot_embeds), len(prot_embeds)), dtype=np.int32)\n",
    "    trlabels[r][c, d] = 1000\n",
    "\n",
    "test_data = load_test_data('data/test/9606.protein.links.v11.0.txt', classes, relations)\n",
    "top1 = 0\n",
    "top10 = 0\n",
    "top100 = 0\n",
    "mean_rank = 0\n",
    "ftop1 = 0\n",
    "ftop10 = 0\n",
    "ftop100 = 0\n",
    "fmean_rank = 0\n",
    "labels = {}\n",
    "preds = {}\n",
    "ranks = {}\n",
    "franks = {}\n",
    "eval_data = test_data\n",
    "n = len(eval_data)\n",
    "for c, r, d in eval_data:\n",
    "    c, r, d = prot_dict[classes[c]], relations[r], prot_dict[classes[d]]\n",
    "    if r not in labels:\n",
    "        labels[r] = np.zeros((len(prot_embeds), len(prot_embeds)), dtype=np.int32)\n",
    "    if r not in preds:\n",
    "        preds[r] = np.zeros((len(prot_embeds), len(prot_embeds)), dtype=np.float32)\n",
    "    labels[r][c, d] = 1\n",
    "    ec = prot_embeds[c, :]\n",
    "    rc = prot_rs[c, :]\n",
    "    er = rembeds[r, :]\n",
    "    ec += er\n",
    "\n",
    "    # Compute similarity\n",
    "    dst = np.linalg.norm(prot_embeds - ec.reshape(1, -1), axis=1)\n",
    "    dst = dst.reshape(-1, 1)\n",
    "    res = np.maximum(0, dst - rc - prot_rs - margin)\n",
    "    res = res.flatten()\n",
    "\n",
    "    preds[r][c, :] = res\n",
    "    index = rankdata(res, method='average')\n",
    "    rank = index[d]\n",
    "    if rank == 1:\n",
    "        top1 += 1\n",
    "    if rank <= 10:\n",
    "        top10 += 1\n",
    "    if rank <= 100:\n",
    "        top100 += 1\n",
    "    mean_rank += rank\n",
    "    if rank not in ranks:\n",
    "        ranks[rank] = 0\n",
    "    ranks[rank] += 1\n",
    "\n",
    "    # Filtered rank\n",
    "    index = rankdata((res * trlabels[r][c, :]), method='average')\n",
    "    rank = index[d]\n",
    "    if rank == 1:\n",
    "        ftop1 += 1\n",
    "    if rank <= 10:\n",
    "        ftop10 += 1\n",
    "    if rank <= 100:\n",
    "        ftop100 += 1\n",
    "    fmean_rank += rank\n",
    "\n",
    "    if rank not in franks:\n",
    "        franks[rank] = 0\n",
    "    franks[rank] += 1\n",
    "top1 /= n\n",
    "top10 /= n\n",
    "top100 /= n\n",
    "mean_rank /= n\n",
    "ftop1 /= n\n",
    "ftop10 /= n\n",
    "ftop100 /= n\n",
    "fmean_rank /= n\n",
    "\n",
    "rank_auc = compute_rank_roc(ranks, len(proteins))\n",
    "frank_auc = compute_rank_roc(franks, len(proteins))\n",
    "\n",
    "print('Evaluation for 9606')\n",
    "print('{0} {1} {2} {3}'.format(top10, top100, mean_rank, rank_auc))\n",
    "print('{0} {1} {2} {3}'.format(ftop10, ftop10000, fmean_rank, frank_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
